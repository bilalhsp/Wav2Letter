# ğŸ—£ï¸ Wav2LetterRF â€” Convolutional ASR Model in PyTorch Lightning

This repository provides an implementation of a modified **Wav2Letter** architecture (`Wav2LetterRF`) for Automatic Speech Recognition (ASR), built using **PyTorch Lightning**. The model is trained using **Connectionist Temporal Classification (CTC)** loss and is trained with the **LibriSpeech** dataset.

---

## ğŸ“¦ Features

- ğŸ§± Fully convolutional architecture for ASR
- ğŸ§ª CTCLoss for alignment-free training
- ğŸ“š Built-in support for LibriSpeech dataset
- ğŸ” Logging of training/validation loss, WER, and CER
- ğŸ“¤ Easy decoding and inference pipeline
- âœ… Ready-to-use pretrained model interface

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/bilalhsp/Wav2Letter.git
cd Wav2Letter
pip install -e .
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ scripts/                    # Training and inference scripts
â””â”€â”€ wav2letter/
    â”‚
    â”œâ”€â”€ datasets.py             # pytorch dataset class for LibriSpeech 
    â”œâ”€â”€ models.py               # Contains Wav2LetterRF model
    â”œâ”€â”€ prepareLibriSpeech.py   # Helper functions for downloadin LibriSpeech         
    â”œâ”€â”€ conf/                   # YAML config files
    â”œâ”€â”€ utils/                  # Helper functions (decoding, evaluation)
    â””â”€â”€ ...
```

---

## ğŸ“š LibriSpeech Support

The repository includes code to:

- âœ… Download LibriSpeech splits
- âœ… Preprocess and prepare dataloaders
- âœ… Tokenize and decode transcripts

---

## ğŸš€ Usage Example

### âœ¨ Load Pretrained Model and Transcribe

```python
from wav2letter.models import Wav2LetterRF
import torch
import torchaudio

# Load pretrained model (update path if needed)
checkpoint = 'path_to_pretrained_weights'
model = Wav2LetterRF.load_from_checkpoint(checkpoint)
model.eval()

# Load and preprocess an audio file
waveform, sample_rate = torchaudio.load("sample.wav")
if sample_rate != 16000:
    waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)
waveform = waveform.squeeze(0)  # Mono

# Transcribe
with torch.no_grad():
    pred_text = model.decode(waveform.unsqueeze(0))
print("Predicted transcription:", pred_text[0])
```

---

## âš™ï¸ Training

To train the model:

```bash
python scripts/run_lightning.py
```

You can customize the YAML config for:

- Learning rate
- Number of channels
- Dataset paths
- Output directory

---

## ğŸ“Š Logging & Evaluation

Validation loss, WER (Word Error Rate), and CER (Character Error Rate) are automatically logged using your preferred logger (e.g., TensorBoard).

---

## ğŸ“ References

- Collobert et al., "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System"
- [LibriSpeech ASR corpus](http://www.openslr.org/12/)

---

## ğŸ“© Contact

For questions or issues, feel free to open an issue or reach out.

